{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg, FedAdagrad\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
    "from flwr.common import Metrics, Context\n",
    "\n",
    "\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "from flwr.client.mod import parameters_size_mod\n",
    "\n",
    "from dmf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.10.0 / PyTorch 2.2.1+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haya/miniconda/envs/fedrec/lib/python3.9/site-packages/flwr_datasets/utils.py:109: UserWarning: The currently tested dataset are ['mnist', 'ylecun/mnist', 'cifar10', 'uoft-cs/cifar10', 'fashion_mnist', 'zalando-datasets/fashion_mnist', 'sasha/dog-food', 'zh-plus/tiny-imagenet', 'scikit-learn/adult-census-income', 'cifar100', 'uoft-cs/cifar100', 'svhn', 'ufldl-stanford/svhn', 'sentiment140', 'stanfordnlp/sentiment140', 'speech_commands', 'LIUM/tedlium', 'flwrlabs/femnist', 'flwrlabs/ucf101', 'flwrlabs/ambient-acoustic-context', 'jlh/uci-mushrooms', 'Mike0307/MNIST-M', 'flwrlabs/usps', 'scikit-learn/iris', 'flwrlabs/pacs', 'flwrlabs/cinic10', 'flwrlabs/caltech101', 'flwrlabs/office-home', 'flwrlabs/fed-isic2019']. Given: ashraq/movielens_ratings.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") \n",
    "NUM_PARTITIONS = 5\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "dataset = \"ashraq/movielens_ratings\" \n",
    "partitioner = IidPartitioner(num_partitions=NUM_PARTITIONS)           \n",
    "fds = FederatedDataset(dataset=dataset,\n",
    "                    partitioners={\"train\": partitioner})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Number of Users: 43584\n",
      "Global Number of Movies: 15276\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Process the Federated Dataset & Global Mapping without interaction matrix\n",
    "########################################\n",
    "\n",
    "def compute_global_mapping(fds):\n",
    "    \"\"\"\n",
    "    Compute global mapping for user and item IDs from the full dataset.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Load the full splits from the FederatedDataset (adjust split names as needed)\n",
    "    global_train_df = fds.load_split(\"train\").to_pandas()[[\"user_id\", \"movie_id\", \"rating\"]]    # Full training data across all clients\n",
    "    global_test_df = fds.load_split(\"validation\").to_pandas()[[\"user_id\", \"movie_id\", \"rating\"]]    # Full test set\n",
    "\n",
    "    # Exclude cold cases from valid/test based solely on training data.\n",
    "    train_users = set(global_train_df['user_id'].unique())\n",
    "    train_movies = set(global_train_df['movie_id'].unique())\n",
    "\n",
    "    global_test_df = global_test_df[\n",
    "        global_test_df['user_id'].isin(train_users) &\n",
    "        global_test_df['movie_id'].isin(train_movies)\n",
    "    ]\n",
    "\n",
    "    # Build the union of all user and movie IDs across splits.\n",
    "    all_users = set(global_train_df['user_id']).union(global_test_df['user_id'])\n",
    "    all_movies = set(global_train_df['movie_id']).union(global_test_df['movie_id'])\n",
    "\n",
    "    # Create mapping dictionaries (zero-based, contiguous indices)\n",
    "    user_id_map = {user: idx for idx, user in enumerate(sorted(all_users))}\n",
    "    movie_id_map = {movie: idx for idx, movie in enumerate(sorted(all_movies))}\n",
    "\n",
    "    num_users = len(user_id_map)\n",
    "    num_movies = len(movie_id_map)\n",
    "    print(\"Global Number of Users:\", num_users)\n",
    "    print(\"Global Number of Movies:\", num_movies)\n",
    "\n",
    "    return user_id_map, movie_id_map,\n",
    "\n",
    "    \n",
    "# Precompute the global mappings and interaction matrix once.\n",
    "global_user_id_map, global_movie_id_map = compute_global_mapping(fds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# DataLoader Setup Using Global Mappings\n",
    "########################################\n",
    "\n",
    "def load_datasets(partition_id: int, batch_size: int, global_user_id_map, global_movie_id_map):\n",
    "    \n",
    "    # Load the partition assigned to this client.\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "\n",
    "    train = partition_train_test[\"train\"].to_pandas()[[\"user_id\", \"movie_id\", \"rating\"]] \n",
    "    valid = partition_train_test[\"test\"].to_pandas()[[\"user_id\", \"movie_id\", \"rating\"]] \n",
    "    \n",
    "    # Filter out rows with IDs that are not in the global mapping (if any).\n",
    "    valid = valid[\n",
    "        valid['user_id'].isin(global_user_id_map) & valid['movie_id'].isin(global_movie_id_map)\n",
    "    ]\n",
    "    \n",
    "    # Create DMFDataset instances using the global mapping.\n",
    "    train_dataset = DMFDataset(train, global_user_id_map, global_movie_id_map)\n",
    "    valid_dataset = DMFDataset(valid, global_user_id_map, global_movie_id_map)\n",
    "\n",
    "    \n",
    "    # Build DataLoaders.\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test = fds.load_split(\"validation\").to_pandas()[[\"user_id\", \"movie_id\", \"rating\"]] \n",
    "\n",
    "    test = test[\n",
    "        test['user_id'].isin(global_user_id_map) & test['movie_id'].isin(global_movie_id_map)\n",
    "    ]\n",
    "\n",
    "    test_dataset = DMFDataset(test, global_user_id_map, global_movie_id_map)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# The model\n",
    "########################################\n",
    "\n",
    "class MLPLayers(nn.Module):\n",
    "    def __init__(self, sizes, dropout=0.3, activation=\"leaky_relu\", bn=False, init_method=\"norm\", last_activation=True):\n",
    "        super(MLPLayers, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 1):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
    "            if bn:\n",
    "                layers.append(nn.BatchNorm1d(sizes[i+1]))\n",
    "            if activation == \"leaky_relu\":\n",
    "                layers.append(nn.LeakyReLU())\n",
    "            else:\n",
    "                layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        if not last_activation:\n",
    "            layers = layers[:-2]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class DMFFederated(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified DMF model that uses learnable embeddings instead of a precomputed global interaction matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_items,\n",
    "                 user_embedding_size=32,\n",
    "                 item_embedding_size=32,\n",
    "                 user_hidden_sizes=[64, 32],\n",
    "                 item_hidden_sizes=[64, 32],\n",
    "                 dropout=0.3,\n",
    "                 activation=\"leaky_relu\",\n",
    "                 bn=False,\n",
    "                 init_method=\"norm\"):\n",
    "        super(DMFFederated, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users, user_embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, item_embedding_size)\n",
    "        \n",
    "        self.user_fc_layers = MLPLayers(\n",
    "            [user_embedding_size] + user_hidden_sizes,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            bn=bn,\n",
    "            init_method=init_method,\n",
    "            last_activation=True\n",
    "        )\n",
    "        self.item_fc_layers = MLPLayers(\n",
    "            [item_embedding_size] + item_hidden_sizes,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            bn=bn,\n",
    "            init_method=init_method,\n",
    "            last_activation=True\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.HuberLoss(delta=0.5)\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, 0, 0.01)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.fill_(0.0)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.normal_(module.weight, 0, 0.01)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "        user_features = self.user_fc_layers(user_emb)\n",
    "        item_features = self.item_fc_layers(item_emb)\n",
    "        prediction = torch.mul(user_features, item_features).sum(dim=1)\n",
    "        return prediction\n",
    "    \n",
    "    def calculate_loss(self, batch):\n",
    "        user = batch['user_id']\n",
    "        item = batch['movie_id']\n",
    "        rating = batch['rating']\n",
    "        preds = self.forward(user, item)\n",
    "        loss = self.loss_fn(preds, rating)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, batch):\n",
    "        return self.forward(batch['user_id'], batch['movie_id'])\n",
    "\n",
    "model = DMFFederated(\n",
    "            num_users=len(global_user_id_map),\n",
    "            num_items=len(global_movie_id_map),\n",
    "            user_embedding_size=32,\n",
    "            item_embedding_size=32,\n",
    "            user_hidden_sizes=[64, 32],\n",
    "            item_hidden_sizes=[64, 32],\n",
    "            dropout=0.3,\n",
    "            activation=\"leaky_relu\",\n",
    "            bn=False,\n",
    "            init_method=\"norm\"\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMFFederated(\n",
      "  (user_embedding): Embedding(43584, 32)\n",
      "  (item_embedding): Embedding(15276, 32)\n",
      "  (user_fc_layers): MLPLayers(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (4): LeakyReLU(negative_slope=0.01)\n",
      "      (5): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (item_fc_layers): MLPLayers(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (4): LeakyReLU(negative_slope=0.01)\n",
      "      (5): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (loss_fn): HuberLoss()\n",
      ")\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "WrappedModel                             [16]                      --\n",
       "├─DMFFederated: 1-1                      [16]                      --\n",
       "│    └─Embedding: 2-1                    [16, 32]                  1,394,688\n",
       "│    └─Embedding: 2-2                    [16, 32]                  488,832\n",
       "│    └─MLPLayers: 2-3                    [16, 32]                  --\n",
       "│    │    └─Sequential: 3-1              [16, 32]                  4,192\n",
       "│    └─MLPLayers: 2-4                    [16, 32]                  --\n",
       "│    │    └─Sequential: 3-2              [16, 32]                  4,192\n",
       "==========================================================================================\n",
       "Total params: 1,891,904\n",
       "Trainable params: 1,891,904\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 30.27\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 7.57\n",
       "Estimated Total Size (MB): 7.60\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# Print model\n",
    "########################################\n",
    "print(model)\n",
    "print(\"-\"*25)\n",
    "\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        return self.base(user_ids, item_ids)\n",
    "\n",
    "wrapped = WrappedModel(model)\n",
    "\n",
    "summary(\n",
    "    wrapped,\n",
    "    input_size=[(16,), (16,)],          \n",
    "    dtypes=[torch.long, torch.long]      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Set and get parameters\n",
    "########################################\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "\n",
    "def set_parameters(model, parameters: List[np.ndarray]):\n",
    "    \"\"\"\n",
    "    Sets the parameters of the model using a list of NumPy arrays.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model.\n",
    "        parameters (List[np.ndarray]): The model parameters as a list of NumPy arrays.\n",
    "    \"\"\"\n",
    "    params_dict = zip(model.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(model) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Retrieves the model parameters as a list of NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: The model parameters as a list of NumPy arrays.\n",
    "    \"\"\"\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Training and Evaluation Functions\n",
    "########################################\n",
    "\n",
    "def train(model, trainloader, epochs: int, lr=0.0001, weight_decay=1e-4, device=\"cpu\"):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        for batch in trainloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.calculate_loss(batch)  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            bs = len(batch['rating'])\n",
    "            total_loss += loss.item() * bs\n",
    "            total_samples += bs\n",
    "        avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        \n",
    "\n",
    "def test(model, dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss = model.calculate_loss(batch)\n",
    "            bs = len(batch['rating'])\n",
    "            total_loss += loss.item() * bs\n",
    "            total_samples += bs\n",
    "    avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "    print(f\"Evaluation Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Inilialize the model \n",
    "########################################\n",
    "\n",
    "model = DMFFederated(\n",
    "            num_users=len(global_user_id_map),\n",
    "            num_items=len(global_movie_id_map),\n",
    "            user_embedding_size=32,\n",
    "            item_embedding_size=32,\n",
    "            user_hidden_sizes=[64, 32],\n",
    "            item_hidden_sizes=[64, 32],\n",
    "            dropout=0.3,\n",
    "            activation=\"leaky_relu\",\n",
    "            bn=False,\n",
    "            init_method=\"norm\"\n",
    "            )\n",
    "\n",
    "params = get_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flwr.client.client_app.ClientApp at 0x7fe18c03ce20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# Flower Client Definition and Client Function\n",
    "########################################\n",
    "torch.cuda.empty_cache()\n",
    "device = DEVICE \n",
    "num_partitions = NUM_PARTITIONS\n",
    "batch_size = BATCH_SIZE\n",
    "num_epochs = 1\n",
    "lr = 0.0001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, model, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        \n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        params = get_parameters(self.model)\n",
    "        return params\n",
    "    \n",
    "   \n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.model, parameters)\n",
    "        train(self.model, self.trainloader, epochs=num_epochs, lr=lr, weight_decay=weight_decay, device=device)\n",
    "        return get_parameters(self.model), len(self.trainloader), {}\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss = test(self.model, self.valloader, device=device)\n",
    "        return float(loss), len(self.valloader), {\"loss\": float(loss)}\n",
    "    \n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "\n",
    "    model = DMFFederated(\n",
    "            num_users=len(global_user_id_map),\n",
    "            num_items=len(global_movie_id_map),\n",
    "            user_embedding_size=32,\n",
    "            item_embedding_size=32,\n",
    "            user_hidden_sizes=[64, 32],\n",
    "            item_hidden_sizes=[64, 32],\n",
    "            dropout=0.3,\n",
    "            activation=\"leaky_relu\",\n",
    "            bn=False,\n",
    "            init_method=\"norm\"\n",
    "            ).to(device)\n",
    "\n",
    "    \n",
    "    trainloader, valloader, _ = load_datasets(\n",
    "        partition_id, batch_size,  global_user_id_map, global_movie_id_map\n",
    "    )\n",
    "\n",
    "    return FlowerClient(partition_id, model, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)\n",
    "client_app "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_DMFRegressor(model, test_loader, device, batch_size=64):\n",
    "    \"\"\"\n",
    "    Evaluate the regression model on the test set.\n",
    "    \n",
    "    Args:\n",
    "        model: The DMFModel (or any regression model) instance that predicts continuous ratings.\n",
    "        test_set: A PyTorch Dataset (e.g., DMFDataset) for testing.\n",
    "        device: The torch.device (e.g., \"cuda\" or \"cpu\").\n",
    "        batch_size (int): Batch size for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "        average_loss: The average loss over the test set.\n",
    "        mae: Mean Absolute Error.\n",
    "        rmse: Root Mean Squared Error.\n",
    "        r2: R^2 score (coefficient of determination).\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss = model.calculate_loss(batch)\n",
    "            bs = len(batch['rating'])\n",
    "            total_loss += loss.item() * bs\n",
    "            total_samples += bs\n",
    "\n",
    "            preds = model.predict(batch)\n",
    "            labels = batch['rating'] \n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    mse = mean_squared_error(all_labels, all_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(all_labels, all_preds)\n",
    "    return avg_loss, mae, rmse, r2\n",
    "\n",
    "\n",
    "def evaluate_testset(\n",
    "    server_round: int,\n",
    "    parameters: NDArrays,\n",
    "    config: Dict[str, Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    model = DMFFederated(\n",
    "            num_users=len(global_user_id_map),\n",
    "            num_items=len(global_movie_id_map),\n",
    "            user_embedding_size=32,\n",
    "            item_embedding_size=32,\n",
    "            user_hidden_sizes=[64, 32],\n",
    "            item_hidden_sizes=[64, 32],\n",
    "            dropout=0.3,\n",
    "            activation=\"leaky_relu\",\n",
    "            bn=False,\n",
    "            init_method=\"norm\"\n",
    "            ).to(device)\n",
    "    \n",
    "    _, _, testloader = load_datasets(0, batch_size,  global_user_id_map, global_movie_id_map)\n",
    "    set_parameters(model, parameters)  # Update model with the latest parameters\n",
    "    loss, mae, rmse, r2 = evaluate_DMFRegressor(model, testloader, device=device)\n",
    "    print(f\"Server-side evaluation loss {loss}, mae {mae}, rmse {rmse}, r2 {r2}\")\n",
    "    return loss, {\"mae\": mae, \"rmse\": rmse, \"r2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flwr.server.server_app.ServerApp at 0x7fe18cf0afa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "\n",
    "    Perform two rounds of training with one local epoch, increase to two local\n",
    "    epochs afterwards.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"server_round\": server_round, \n",
    "        \"local_epochs\": 15 \n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "num_rounds = 10\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Create FedAvg strategy\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=1,\n",
    "        fraction_evaluate=1,\n",
    "        min_fit_clients=NUM_PARTITIONS,\n",
    "        min_evaluate_clients=NUM_PARTITIONS,\n",
    "        min_available_clients=NUM_PARTITIONS,\n",
    "        initial_parameters=ndarrays_to_parameters(params),\n",
    "        on_fit_config_fn=fit_config,  \n",
    "        evaluate_fn=evaluate_testset\n",
    "    )\n",
    "    config = ServerConfig(num_rounds=num_rounds)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "backend_config = {\"client_resources\": None}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_gpus\": 2, \"num_cpus\": 1}}\n",
    "\n",
    "\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "server_app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 1.6509557969292865, {'mae': 3.5519116, 'rmse': 3.7049718, 'r2': -11.3582637099747}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.6509557969292865, mae 3.5519115924835205, rmse 3.7049717903137207, r2 -11.3582637099747\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 1, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 1.0262\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 1, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 1.0219\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 1, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 1.0210\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 1, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 1.0218\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 1, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 1.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.3247440861144296, {'mae': 0.8704794, 'rmse': 1.0809022, 'r2': -0.051866331545187494}, 38.4257799545303)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.3247440861144296, mae 0.8704794049263, rmse 1.0809022188186646, r2 -0.051866331545187494\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.3245\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.3240\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.3271\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.3267\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.3242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 2, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3891\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 2, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3888\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 2, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3893\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 2, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3889\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 2, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.2657425680093519, {'mae': 0.74401677, 'rmse': 0.9591132, 'r2': 0.17181493816809956}, 91.90311167575419)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.2657425680093519, mae 0.7440167665481567, rmse 0.9591131806373596, r2 0.17181493816809956\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2668\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2665\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2642\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2651\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2640\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 3, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3697\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 3, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3687\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 3, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3702\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 3, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3710\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 3, 'local_epochs': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3713\n",
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.2501269211374372, {'mae': 0.710353, 'rmse': 0.9248919, 'r2': 0.22986014743641536}, 143.3553984630853)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.2501269211374372, mae 0.7103530168533325, rmse 0.9248918890953064, r2 0.22986014743641536\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2514\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2490\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2498\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2487\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2508\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 4, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3589\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 4, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3597\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 4, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3609\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 4, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3616\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 4, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.24351011577288112, {'mae': 0.69579166, 'rmse': 0.91019136, 'r2': 0.2541473395907127}, 195.9987285360694)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.24351011577288112, mae 0.6957916617393494, rmse 0.9101913571357727, r2 0.2541473395907127\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2424\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2432\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2424\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2448\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2442\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 5, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3527\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 5, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3547\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 5, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3550\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 5, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3536\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 5, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.2397434278478704, {'mae': 0.6877421, 'rmse': 0.90242386, 'r2': 0.2668231188948442}, 248.39820314384997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.2397434278478704, mae 0.6877421140670776, rmse 0.9024238586425781, r2 0.2668231188948442\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2394\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2407\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2388\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2411\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2388\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 6, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3508\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 6, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3499\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 6, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3503\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 6, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3509\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 6, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 0.23693703850767125, {'mae': 0.6815271, 'rmse': 0.8972071, 'r2': 0.27527528044171035}, 300.9214560575783)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.23693703850767125, mae 0.6815270781517029, rmse 0.8972070813179016, r2 0.27527528044171035\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2375\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2368\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2381\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2362\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2360\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 7, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3490\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 7, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3470\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 7, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3474\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 7, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3480\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 7, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 0.23553123856894692, {'mae': 0.6784557, 'rmse': 0.8941966, 'r2': 0.2801306002583911}, 353.2413227446377)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.23553123856894692, mae 0.6784557104110718, rmse 0.894196629524231, r2 0.2801306002583911\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2351\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2344\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2365\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2361\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2347\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 8, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3468\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 8, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3448\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 8, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3449\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 8, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3455\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 8, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 0.23432214083749603, {'mae': 0.6755894, 'rmse': 0.8920587, 'r2': 0.28356882971245334}, 405.68140666745603)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.23432214083749603, mae 0.675589382648468, rmse 0.8920586705207825, r2 0.28356882971245334\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2342\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2334\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2338\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2353\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 9, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3444\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 9, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3435\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 9, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3433\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 9, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3451\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 9, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 0.23525785524034815, {'mae': 0.67808443, 'rmse': 0.8923648, 'r2': 0.2830770336936308}, 457.9919637851417)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.23525785524034815, mae 0.6780844330787659, rmse 0.8923647999763489, r2 0.2830770336936308\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2366\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2348\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2351\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2343\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2359\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] fit, config: {'server_round': 10, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3417\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] fit, config: {'server_round': 10, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3416\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] fit, config: {'server_round': 10, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3435\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] fit, config: {'server_round': 10, 'local_epochs': 15}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3433\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] fit, config: {'server_round': 10, 'local_epochs': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Epoch 1/1, Training Loss: 0.3438\n",
      "(142621, 3) (35656, 3) (98138, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 0.2354739606866347, {'mae': 0.6783642, 'rmse': 0.8923807, 'r2': 0.28305148623620524}, 509.3466588156298)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.2354739606866347, mae 0.6783642172813416, rmse 0.8923807144165039, r2 0.28305148623620524\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2344\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2365\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142621, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2350\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2358\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m (142620, 3) (35656, 3) (98138, 3)\n",
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 527.51s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.3252923802393874\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.2653364297036823\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.24994945465408422\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.24340145983034273\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.23976447070182536\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.23691898496436622\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.23535550273812775\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.23433053093304781\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.23534000892729565\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.23531724695122133\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 1.6509557969292865\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.3247440861144296\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.2657425680093519\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.2501269211374372\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.24351011577288112\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.2397434278478704\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.23693703850767125\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.23553123856894692\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.23432214083749603\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.23525785524034815\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.2354739606866347\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'mae': [(0, 3.5519116),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (1, 0.8704794),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (2, 0.74401677),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (3, 0.710353),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (4, 0.69579166),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (5, 0.6877421),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (6, 0.6815271),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (7, 0.6784557),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (8, 0.6755894),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (9, 0.67808443),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (10, 0.6783642)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'r2': [(0, -11.3582637099747),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (1, -0.051866331545187494),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (2, 0.17181493816809956),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (3, 0.22986014743641536),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (4, 0.2541473395907127),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (5, 0.2668231188948442),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (6, 0.27527528044171035),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (7, 0.2801306002583911),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (8, 0.28356882971245334),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (9, 0.2830770336936308),\n",
      "\u001b[92mINFO \u001b[0m:      \t        (10, 0.28305148623620524)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'rmse': [(0, 3.7049718),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (1, 1.0809022),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (2, 0.9591132),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (3, 0.9248919),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (4, 0.91019136),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (5, 0.90242386),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (6, 0.8972071),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (7, 0.8941966),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (8, 0.8920587),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (9, 0.8923648),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (10, 0.8923807)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ClientAppActor pid=2480272)\u001b[0m Evaluation Loss: 0.2350\n",
      "Simulation took 539.3246395587921 second to finish\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Simulation\n",
    "########################################\n",
    "\n",
    "import time\n",
    "\n",
    "before_sim_start = time.time()\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config \n",
    ")\n",
    "\n",
    "after_sim_start = time.time()\n",
    "print(f\"Simulation took {after_sim_start - before_sim_start} second to finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedRec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
